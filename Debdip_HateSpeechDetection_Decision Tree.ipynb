{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eeb9ef1-9dda-4993-bddd-36b196209d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f845ee1-6b3e-442b-a48c-efceb050db40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KIIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import pr\n",
    "nltk.download('stopwords')  # Download stopwords\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "472af2dc-c58a-451a-a5c5-cdeeb25a505f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Import Pandas\n",
    "\n",
    "df = pd.read_csv('twitter_data.csv')  # Load CSV file\n",
    "print(df.head())  # Display first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3045cbbc-42b4-4270-9dd1-dc29addd597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                         labels  \n",
      "0  No Hate and Offensive Speech  \n",
      "1   Offensive Language Detected  \n",
      "2   Offensive Language Detected  \n",
      "3   Offensive Language Detected  \n",
      "4   Offensive Language Detected  \n"
     ]
    }
   ],
   "source": [
    "df['labels'] = df['class'].map({\n",
    "    0: \"Hate Speech Detected\", \n",
    "    1: \"Offensive Language Detected\", \n",
    "    2: \"No Hate and Offensive Speech\"  # Fixed key from '3' to '2' (if needed)\n",
    "})  # Closing both `}` and `)`\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2a071b-991c-44b3-89e2-a2ec12bae9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  rt mayasolov woman shouldnt complain clean hou...  \n",
      "1   rt boy dat coldtyga dwn bad cuffin dat hoe place  \n",
      "2  rt urkindofbrand dawg rt ever fuck bitch start...  \n",
      "3             rt cganderson vivabas look like tranni  \n",
      "4  rt shenikarobert shit hear might true might fa...  \n"
     ]
    }
   ],
   "source": [
    "# Define text cleaning function\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Use raw string (r'...')\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in text.split() if word not in stopword]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    # Apply stemming\n",
    "    words = [stemmer.stem(word) for word in text.split()]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Load CSV\n",
    "import pandas as pd\n",
    "df = pd.read_csv('twitter_data.csv')\n",
    "\n",
    "# Apply cleaning function\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(clean)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff1863fc-6e2d-47dd-b481-ed4506b92e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame: Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n",
      "       'class', 'tweet', 'labels'],\n",
      "      dtype='object')\n",
      "Model training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Ensure labels column exists\n",
    "if 'labels' not in df.columns:\n",
    "    df['labels'] = df['class'].map({\n",
    "        0: \"Hate Speech Detected\", \n",
    "        1: \"Offensive Language Detected\", \n",
    "        2: \"No Hate and Offensive Speech\"\n",
    "    })\n",
    "\n",
    "# Check available columns\n",
    "print(\"Columns in DataFrame:\", df.columns)\n",
    "\n",
    "# Convert DataFrame columns to NumPy arrays\n",
    "x = np.array(df[\"tweet\"])  \n",
    "y = np.array(df[\"labels\"])\n",
    "\n",
    "# Vectorize text data\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(x)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Train Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f421ee0a-e0ba-4c6e-b699-b27726ae4d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Offensive Language Detected']\n"
     ]
    }
   ],
   "source": [
    "test_data= \"I will kill you\"\n",
    "df = cv.transform([test_data]).toarray()\n",
    "print(clf.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be701160-9b45-433f-84a7-ae4ddff8ab4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive Speech']\n"
     ]
    }
   ],
   "source": [
    "test_data= \"He is not a good boy\"\n",
    "df = cv.transform([test_data]).toarray()\n",
    "print(clf.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22c87e-6648-47ca-8f5d-01cb9ff6e702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
